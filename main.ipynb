import cv2
from deepface import DeepFace
import numpy as np
import cv2
from IPython import display
from io import StringIO
from PIL import Image
import matplotlib.pyplot as py
%matplotlib inline



faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    exit()
    
while True:
    ret, frame = cap.read()
    
    result = DeepFace.analyze(frame, enforce_detection=False)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    faces = faceCascade.detectMultiScale(gray, 1.5, 4)
    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (100, 0, 255), 2)
        n_gray = gray[y:y+w, x:x+w]
        n_color = frame[y:y+h, x:x+w]
        eyes = eyeCascade.detectMultiScale(n_gray, 1.5, 4)
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(n_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)
        
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(frame, result['dominant_emotion'], (80, 100), font, 2, (0, 0, 255), 2, cv2.LINE_4)
    
#     half_frame = cv2.resize(frame, (0, 0), fx = 0.5, fy = 0.5)
#             _,ret_array = cv2.imencode('.jpg', half_frame) 
#             i = display.Image(data=ret_array)
#             display.display(i)

    cv2.imshow('Test Trial', frame)
    
    if cv2.waitKey(2) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
